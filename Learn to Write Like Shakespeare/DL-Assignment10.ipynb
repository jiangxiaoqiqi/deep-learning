{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aq9LbvGHZSr_"
   },
   "source": [
    "Assignment 10: Learn to Write Like Shakespeare\n",
    "==============================================\n",
    "\n",
    "\n",
    "Microsoft Forms Document: https://forms.office.com/r/xs1Xb1pe3g\n",
    "\n",
    "In this assignment we will implement a simple recurrent network with one hidden layer.\n",
    "We train this network on a medium-size poem \"The Sonnet\" written by William Shakespeare and use it for auto-completing sentences/phrases.\n",
    "\n",
    "The data that we will use is originally provided here: http://raw.githubusercontent.com/brunoklein99/deep-learning-notes/master/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1654727290053,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "FxhptfExZSsB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# download the data file\n",
    "filename = \"shakespeare.txt\"\n",
    "if not os.path.exists(filename):\n",
    "  url = \"http://raw.githubusercontent.com/brunoklein99/deep-learning-notes/master/\"\n",
    "  import urllib.request\n",
    "  urllib.request.urlretrieve(url+filename, filename)\n",
    "  print (\"Downloaded datafile\", filename)\n",
    "\n",
    "# select to run everything on CUDA\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5UUm5d_ZSsC"
   },
   "source": [
    "We need to parse the data and turn it into a representation from which we can learn.\n",
    "First, we need to count the number of unique characters to obtain the dimension $D$ of out input and output.\n",
    "Then, we need to obtain one-hot encoding vectors for each of the characters.\n",
    "Finally, we need to implement sequences and their according targets, using zero-padding where required.\n",
    "\n",
    "Task 1: Data Characteristics\n",
    "----------------------------\n",
    "\n",
    "Load all text data from the file `shakespeare.txt`.\n",
    "Count the number of unique characters contained in the poem. \n",
    "Here, we consider only lower-case characters to reduce the alphabet size.\n",
    "At the same time, we also store the complete poem in a data variable.\n",
    "\n",
    "Please make sure that you handle the newline character at the end of each line correctly and consistently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1654727290545,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "PHJfiKttZSsC",
    "outputId": "ef4241a9-011e-4080-9ec6-392c198c35e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected a total of 93717 elements of 37 unique characters\n"
     ]
    }
   ],
   "source": [
    "# load all data from the text file\n",
    "data = []\n",
    "count = 0\n",
    "with open(filename,\"r\") as f: ### data = ' '.join(f.read().lower().split())\n",
    "  for line in f:\n",
    "    if (line.strip()): ### 如果不是空行。 strip() 把换行符也删了；rstrip() 只删空格\n",
    "      for c in line.lower().strip():\n",
    "        data.append(c)\n",
    "      data.append(\" \")\n",
    "\n",
    "# extract a list of all unique characters\n",
    "characters = list(sorted(set(data)))\n",
    "\n",
    "D = len(characters)\n",
    "print (f\"Collected a total of {len(data)} elements of {D} unique characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb-uxWSYZSsC"
   },
   "source": [
    "Task 2: One-hot Encoding\n",
    "------------------------\n",
    "\n",
    "Each of the characters need to be represented by a one-hot encoding.\n",
    "Create a dictionary that provides the encoding for each unique character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1654727290545,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "BB0xfPPMZSsC"
   },
   "outputs": [],
   "source": [
    "one_hot = dict()\n",
    "eye = torch.eye(D)\n",
    "for i,c in enumerate(characters):\n",
    "  one_hot[c] = eye[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBq_L6AOZSsD"
   },
   "source": [
    "Task 3: Sequence Coding\n",
    "-----------------------\n",
    "\n",
    "Write a function that provides the inputs and targets for a given sequence of the specified sequence length.\n",
    "The last value of the target sequence should be the character of the given index.\n",
    "If a character would be requested from outside of the data range, prepend the inputs (and the targets) with 0.\n",
    "Assure that $\\vec t^{\\{s\\}} = \\vec x^{\\{s+1\\}}$ $\\forall s<S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1654727290545,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "DnLYtCo8ZSsD"
   },
   "outputs": [],
   "source": [
    "def sequence(index, S):\n",
    "  # collect both input and target encodings\n",
    "  inputs, targets = [], []\n",
    "  # go through the sequence and turn characters into encodings\n",
    "  zeros = torch.zeros(D)\n",
    "  for i in range(index - S, index):\n",
    "    inputs.append(one_hot[data[i]] if i >= 0 else zeros)\n",
    "    targets.append(one_hot[data[i+1]] if i+1 >= 0 else zeros)\n",
    "  \n",
    "  return torch.stack(inputs), torch.stack(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyN4S32hZSsE"
   },
   "source": [
    "Test 1: Sequences\n",
    "-----------------\n",
    "\n",
    "Get a sequence for size 5 with index 2. Assure that the data and target vectors are as desired, i.e., the first elements are 0 vectors, and later one-hot encoded data is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1654727290546,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "3yp1-bt1ZSsE",
    "outputId": "448df28e-fad2-4187-8410-591865597145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "t:\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n"
     ]
    }
   ],
   "source": [
    "# get sequence\n",
    "x,t = sequence(index=2,S=5)\n",
    "print(\"x:\\n\",x)\n",
    "print(\"t:\\n\",t)\n",
    "# perform checks\n",
    "assert torch.all(x[:3] == 0)\n",
    "assert torch.all(t[:2] == 0)\n",
    "assert torch.all(torch.sum(x[3:],axis=1) == 1) ### torch.sum(x[3:],axis=1) => [1, 1] 所以要 torch.all( [1,1] ) == 1\n",
    "assert torch.all(torch.sum(t[2:],axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siw0mRjvZSsE"
   },
   "source": [
    "We use the standard data loader with a batch size of $B=256$. Theoretically, each training sample could have its own sequence length $S$. To enable batch processing, the sequence size must be the same for each element in the batch (otherwise it cannot be transformed as one large tensor). Thus, our dataset needs to have a fixed sequence size $S$.\n",
    "\n",
    "我们使用标准的数据加载器，批量大小为𝐵=256。理论上，每个训练样本可以有自己的序列长度𝑆。为了能够进行批处理，批中的每个元素的序列大小必须相同（否则不能转化为一个大张量）。因此，我们的数据集需要有一个固定的序列尺寸𝑆。\n",
    "\n",
    "Task 4: Dataset and Data Loader\n",
    "-------------------------------\n",
    "Implement a dataset that takes parameters $N$ (size of the dataset) and $S$ (size of the sequence).\n",
    "In the `__getitem__` function, return the `sequence` (using the function of Task 3) for the sample with the given index, i.e., both the input and the target sequence.\n",
    "\n",
    "实现一个数据集，它需要参数𝑁（数据集的大小）和𝑆（序列的大小）。在__getitem__函数中，返回具有给定索引的样本的序列（使用任务3的函数），即输入序列和目标序列都是如此。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1654727290546,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "zLhREbxAZSsE"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, data, S):\n",
    "    self.S = S\n",
    "    self.data = data ### self.data 就是 dataset当中的关键字\n",
    "    self.N = len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return sequence(index, self.S) ### x and t ∈ (S,D)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.N\n",
    "\n",
    "B = 256\n",
    "S = 20\n",
    "dataset = Dataset(data=data, S=S)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=B, shuffle=True) # why shuffle True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5LF-SW3ZSsF"
   },
   "source": [
    "Test 2: Data Sizes\n",
    "------------------\n",
    "\n",
    "Check that all samples in the dataset have the desired size and behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 2858,
     "status": "ok",
     "timestamp": 1654727293402,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "HF7nISUeZSsF"
   },
   "outputs": [],
   "source": [
    "# S = random.choice(range(1,20)) ### 不能加到 for loop 里面，会出错。\n",
    "# dataset.S = S\n",
    "for x,t in data_loader:\n",
    "  # check that the data and targets are as expected\n",
    "  assert x.shape[0] <= B and x.shape[1] == S and x.shape[2] == D\n",
    "  assert t.shape[0] <= B and t.shape[1] == S and t.shape[2] == D\n",
    "  assert torch.all(x[:,1:,:] == t[:,:-1,:]) ### (B,S,D) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-31BI1HlZSsF"
   },
   "source": [
    "Task 5: Elman Network Implementation\n",
    "------------------------------------\n",
    "\n",
    "Manually implement an Elman network using one fully-connected layer for hidden, recurrent and output units.\n",
    "\n",
    "Implement the processing of the input in the Elman network. Make sure that logit values are computed and returned for each element in the sequence. Try to use as much tensor processing as possible. Remember the shape of $X$ is $B\\times S\\times D$, and when going through the sequence, we need to process $\\vec x^{\\{s\\}}$ separately, while working on all batch elements simultaneously.\n",
    "\n",
    "使用一个全连接层的隐藏单元、循环单元和输出单元，手动实现一个埃尔曼网络。\n",
    "\n",
    "在埃尔曼网络中实现对输入的处理。确保计算并返回序列中每个元素的logit值。尽量使用尽可能多的张量处理。记住𝑋的形状是𝐵×𝑆×𝐷，当通过序列时，我们需要分别处理𝑥⃗{𝑠}，同时对所有批处理元素进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1654727293402,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "1wfk_3u8ZSsF"
   },
   "outputs": [],
   "source": [
    "class ElmanNetwork(torch.nn.Module):\n",
    "  def __init__(self, D, K):\n",
    "    super(ElmanNetwork,self).__init__()\n",
    "    self.W1 = torch.nn.Linear(in_features=D, out_features=K)\n",
    "    self.Wr = torch.nn.Linear(in_features=K, out_features=K)\n",
    "    self.W2 = torch.nn.Linear(in_features=K, out_features=D)\n",
    "    self.activation = torch.nn.PReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # get the shape of the data\n",
    "    B, S, D = x.shape\n",
    "    # initialize the hidden vector in the desired size with 0\n",
    "    # remember to put it on the device\n",
    "    h_s = torch.zeros(B, self.Wr.in_features, device=device)    ### 注意！！！h 有个 batch_size 在前面！！！\n",
    "    # store all logits (we will need them in the loss function)\n",
    "    Z = torch.empty(x.shape, device=device)\n",
    "    # iterate over the sequence\n",
    "    for s in range(S):\n",
    "      # use current sequence item\n",
    "      x_s = x[:,s,:]\n",
    "      # print(x_s.shape) # (batch_size, D)\n",
    "      # compute recurrent activation\n",
    "      a_s = self.W1(x_s) + self.Wr(h_s)\n",
    "      # print(a_s.shape) # (batch_size, K)\n",
    "      # apply activation function\n",
    "      h_s = self.activation(a_s) # (batch_size, K)\n",
    "      # compute logit values\n",
    "      z = self.W2(h_s) # (batch_size, K)\n",
    "      # store logit value\n",
    "      Z[:,s] = z ### Z ∈ (K, S)\n",
    "      \n",
    "    # return logits for all sequence elements\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOQ8iXupZSsF"
   },
   "source": [
    "Test 3: Network Output\n",
    "----------------------\n",
    "\n",
    "Instantiate an Elman network with arbitrary numbers for $D$ and $K$.\n",
    "Generate training samples in a given format, forward them through the network and assure that the results are in the required dimensionality.\n",
    "\n",
    "用任意的数字𝐷和𝐾实例化一个Elman网络。以给定的格式生成训练样本，通过网络转发，并保证结果符合要求的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1654727293402,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "WEswsVjcZSsF",
    "outputId": "dfaaff8b-259e-40d3-a0fb-d39b86db9550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 20, 37])\n",
      "torch.Size([256, 20, 37])\n"
     ]
    }
   ],
   "source": [
    "# instantiate test network\n",
    "K = 1000\n",
    "test_network = ElmanNetwork(D=D, K=K).to(device)\n",
    "\n",
    "# create test input in size BxSxD\n",
    "test_input = next(iter(data_loader))[0].to(device)\n",
    "# get the network output\n",
    "with torch.no_grad():\n",
    "  test_output = test_network(test_input)\n",
    "# check that the netowrk output size is as intended\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)\n",
    "assert test_output.shape == ( data_loader.batch_size, S, D ) # data_loader.batch_size 不等于 len(data_loader) 后者是 for loop 中的迭代次数，也就是 batch的个数 而不是size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPl7ejCyZSsF"
   },
   "source": [
    "To train the Elman network, we will use categorical cross-entropy loss, averaged over all samples in the sequence.\n",
    "For each batch, we will use a different sequence size -- while the size inside a batch must stay the same.\n",
    "\n",
    "According to the PyTorch documentation, the `CrossEntropyLoss` handles logits and targets in shape $B\\times O\\times\\ldots$.\n",
    "In our case, logits and targets are in dimension $B\\times S\\times O$.\n",
    "Hence, we need to make sure that we re-order the indexes such that we fulfil the requirement; you might want to use the `permute` operator.\n",
    "\n",
    "WARNING: `CrossEntropyLoss` will not complain when the order for the `CrossEntropyLoss` is wrong, just the results will be wrong.\n",
    "\n",
    "为了训练Elman网络，我们将使用分类交叉熵损失，对序列中的所有样本取平均值。对于每个批次，我们将使用不同的序列大小--而一个批次内的大小必须保持不变。\n",
    "\n",
    "根据PyTorch的文档，CrossEntropyLoss处理对数和目标的形状为𝐵×𝑂×...。在我们的例子中，对数和目标的维度是𝐵×𝑆×𝑂。因此，我们需要确保对索引进行重新排序，以便满足要求；你可能想使用permute操作符。\n",
    "\n",
    "警告：当CrossEntropyLoss的顺序不对时，CrossEntropyLoss不会抱怨，只是结果会出错。\n",
    "\n",
    "\n",
    "Task 6: Training Loop\n",
    "---------------------\n",
    "Instantiate the optimizer with an appropriate learning rate $\\eta$ and the loss function.\n",
    "Implement the training loop for 10 epochs -- more epochs will further improve the results.\n",
    "Compute the average training loss per epoch.\n",
    "Possibly, at the end of each batch, overwrite the `dataset.S` with a value randomly samples from $S\\in[5,20]$.\n",
    "\n",
    "Note that 10 epochs will train for about 2 minutes, if implemented in an optimized way, on the GPU. Non-optimized training will take considerably longer.\n",
    "\n",
    "用适当的学习率𝜂和损失函数实例化优化器。执行10个epochs的训练循环 -- 更多的epochs将进一步改善结果。计算每个epoch的平均训练损失。可能的话，在每个批次结束时，用一个从𝑆∈[5,20]中随机抽取的值覆盖dataset.S。\n",
    "\n",
    "请注意，如果以优化的方式实施，在GPU上，10个epochs将训练大约2分钟。非优化的训练将需要相当长的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159403,
     "status": "ok",
     "timestamp": 1654727452801,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "ObZZ7EoCZSsG",
    "outputId": "5b9f6fe2-bdc1-4581-ca0c-c7b521e075e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1; train loss: 2.15294\n",
      "Epoch 2; train loss: 1.71587\n",
      "Epoch 3; train loss: 1.52859\n",
      "Epoch 4; train loss: 1.41165\n",
      "Epoch 5; train loss: 1.32480\n",
      "Epoch 6; train loss: 1.23157\n",
      "Epoch 7; train loss: 1.16829\n",
      "Epoch 8; train loss: 1.11256\n",
      "Epoch 9; train loss: 1.08249\n",
      "Epoch 10; train loss: 1.06097\n",
      "Epoch 11; train loss: 1.03297\n",
      "Epoch 12; train loss: 1.00243\n",
      "Epoch 13; train loss: 0.99852\n",
      "Epoch 14; train loss: 0.96766\n",
      "Epoch 15; train loss: 0.98447\n",
      "Epoch 16; train loss: 0.95497\n",
      "Epoch 17; train loss: 0.98428\n",
      "Epoch 18; train loss: 1.00163\n",
      "Epoch 19; train loss: 0.96371\n",
      "Epoch 20; train loss: 0.95873\n",
      "Epoch 21; train loss: 0.93242\n",
      "Epoch 22; train loss: 0.91882\n",
      "Epoch 23; train loss: 0.95166\n",
      "Epoch 24; train loss: 0.93091\n",
      "Epoch 25; train loss: 0.94757\n",
      "Epoch 26; train loss: 0.89890\n",
      "Epoch 27; train loss: 0.91782\n",
      "Epoch 28; train loss: 0.93805\n",
      "Epoch 29; train loss: 0.96914\n",
      "Epoch 30; train loss: 0.93104\n"
     ]
    }
   ],
   "source": [
    "network = ElmanNetwork(D=D, K=K).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=network.parameters(),\n",
    "    lr=1e-3\n",
    ")\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "  # create random sequence\n",
    "  train_loss = 0.\n",
    "\n",
    "  for x, t in data_loader:\n",
    "    optimizer.zero_grad()\n",
    "    # compute network output\n",
    "    z = network(x.to(device))\n",
    "    # compute loss, arrange order of logits and targets\n",
    "    z = torch.permute(z, (0, 2, 1))\n",
    "    t = torch.permute(t, (0, 2, 1)).to(device)\n",
    "    J = loss(z,t)\n",
    "    # compute gradient for this batch\n",
    "    J.backward()\n",
    "    # ------------------------------------------\n",
    "    optimizer.step()   ###### 这个一定别忘了!!!!!!\n",
    "    # ------------------------------------------\n",
    "    # compute average loss\n",
    "    train_loss += J.item() ### += J.item()\n",
    "    # select a new sequence length S in [5,20]\n",
    "    dataset.S = random.choice(range(5,21))\n",
    "\n",
    "  # print average loss for training and validation\n",
    "  print(f\"\\rEpoch {epoch+1}; train loss: {train_loss/len(data_loader):1.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63x1PIsIZSsG"
   },
   "source": [
    "Task 7: Text Encoding\n",
    "---------------------\n",
    "For a given text (a sequence of $S$ characters), provide the encoding $\\mathcal X \\in R^{B\\times S\\times D}$.\n",
    "Assure that the batch index $B=1$ is added to the encoding, so that the network is able to handle it.\n",
    "\n",
    "对于一个给定的文本（一串𝑆字符），提供编码 $\\mathcal X \\in R^{B\\times S\\times D}$。确保在编码中加入批索引𝐵=1，以便网络能够处理它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1654729668821,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "VkeJjjrfZSsG",
    "outputId": "94541fc0-0794-49e1-f2de-270c31c72338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 37])\n"
     ]
    }
   ],
   "source": [
    "def encode(text):\n",
    "  # S = len(text)\n",
    "  # x,_ = sequence(index=S,S=S) ### 不能直接用 sequence 啊, 前面写的 sequence 用了一个全局变量 data\n",
    "  encoding = torch.stack([one_hot[c] for c in text]).unsqueeze(dim=0)\n",
    "  return encoding\n",
    "\n",
    "print(encode(\"abc\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdUk9nZOZSsG"
   },
   "source": [
    "Task 8: Next Element Prediction\n",
    "-------------------------------\n",
    "\n",
    "Implement a function that return the next character from the logits returned by the network.\n",
    "Note that the logits are in dimension $\\mathcal Y \\in \\mathbb R^{B\\times S\\times D}$ with $B=1$, and we are generally only interested in the prediction for the last sequence item.\n",
    "\n",
    "实现一个函数，从网络返回的logits中返回下一个字符。注意，logits的维度为$\\mathcal Y \\in \\mathbb R^{B\\times S\\times D}$，其中𝐵=1，我们一般只对最后一个序列项的预测感兴趣。\n",
    "\n",
    "Select the character with the highest SoftMax probability $\\max_o z^{\\{S\\}}_o$ and append this character to the `text`.\n",
    "Alternatively, we can also randomly draw a character based on the SoftMax probability distribution $\\vec y^{\\{S\\}}$. `random.choices` provides the possibility to pass a list of characters and a list of probabilities.\n",
    "\n",
    "选择具有最高SoftMax概率的字符$\\max_o z^{\\{S\\}}_o$，并将此字符追加到文本中。\n",
    "另外，我们也可以根据SoftMax概率分布 $\\vec y^{\\{S\\}}$. 随机抽取一个字符。`random.choice`提供了传递一个字符列表和一个概率列表的可能性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1654729670513,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "MuQ66qLMZSsG"
   },
   "outputs": [],
   "source": [
    "def predict(z, use_best): ### z.shape = (B,S,D) 在这里 B = 1\n",
    "  # select the appropriate logits\n",
    "  z_S = z[0][-1] ### B=1 所以[0] 取到(S,D); 因为只对最后一个 logits 感兴趣，所以取到[D], s 是最后一个 character\n",
    "  if use_best:\n",
    "    # take character with maximum probability\n",
    "    max_idx = torch.argmax(z_S)\n",
    "    next_char = characters[max_idx]\n",
    "  else:\n",
    "    # sample character based on class probabilities\n",
    "        ###### 如果不写 dim=0 会怎么样？ 会报错； 这样写也可以 y_S = torch.nn.Softmax(dim=0)(z_S)\n",
    "        ###### 如果不写.cpu() 会怎么样？ 也不会怎么样, 最好还是写上吧\n",
    "    y_S = torch.softmax(z_S, dim=0).cpu()\n",
    "    next_char = random.choices(characters, weights=y_S)[0] ####### 这里要按权重抽样，必须写 random.choices(xxx, weights=) 别忘了【s】!!! 其返回的是一个list！！！\n",
    "  return next_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvHchK2lZSsG"
   },
   "source": [
    "Task 9: Sequence Completion\n",
    "---------------------------\n",
    "\n",
    "Write a function that takes a `seed` text which it will complete with the given number of characters.\n",
    "Write a loop that turns the current `text` into an encoded sequence of its characters using the function from Task 7.\n",
    "Forward the text through the network and take the prediction of the last sequence item $\\vec z^{\\{S\\}}$ using the function from Task 8.\n",
    "Append this to the current text (remember that Python strings are immutable).\n",
    "Repeat this loop 80 times, and return the resulting `text`.\n",
    "\n",
    "编写一个函数，接收一个种子文本，它将用给定的字符数完成。编写一个循环，使用任务7中的函数将当前文本变成其字符的编码序列。通过网络转发文本，并使用任务8中的函数对最后一个序列项𝑧⃗ {𝑆}进行预测。将其追加到当前文本中（记住，Python字符串是不可改变的）。重复这个循环80次，并返回结果文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1654729671952,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "AUBP-T_iZSsG"
   },
   "outputs": [],
   "source": [
    "def sequence_completion(seed, count, use_best):\n",
    "  # we start with the given seed\n",
    "  text = seed\n",
    "  print(seed)\n",
    "  for i in range(count):\n",
    "    # turn current text to one-hot batch\n",
    "    x = encode(text) ### 这里要把持续增加序列的 text encode 成为 one_hot 序列 (B,S,D); B = 1,S++\n",
    "    z = network(x.to(device)).cpu()\n",
    "    # predict the next character\n",
    "    next_char = predict(z, use_best)\n",
    "    # append character to text\n",
    "    text += next_char\n",
    "    \n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeYAOeGiZSsG"
   },
   "source": [
    "Task 10: Text Production\n",
    "-----------------------\n",
    "\n",
    "Select several seeds (such as `\"the \", \"beau\", \"mothe\", \"bloo\"`) and let the network predict the following 80 most probable characters, or using probability sampling.\n",
    "Write the completed sentences to console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4710,
     "status": "ok",
     "timestamp": 1654729697960,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "XCjA0uEdZSsG",
    "outputId": "d2ebacc4-47c4-4dfb-e335-e6341a3eea8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the \n",
      "\"the \" -> \"the stars in secr true to his sweet up-locked treasure, now count not all the better\"\n",
      "the \n",
      "\"the \" -> \"the othes that i before have what should it as the part, then love be taken to hell \"\n",
      "\n",
      "beau\n",
      "\"beau\" -> \"beauty's summer dead. let not my love be called idole mounning doas disgrace. theref\"\n",
      "beau\n",
      "\"beau\" -> \"beauty hath a face hate the imbubutation i not fleese mighod, so thou preceither we \"\n",
      "\n",
      "mothe\n",
      "\"mothe\" -> \"mother's child, though not true, and thine eyes my knowledge thee, where be nothing n\"\n",
      "mothe\n",
      "\"mothe\" -> \"mother's child of mine can say more that like of hearta thould example where you were\"\n",
      "\n",
      "bloo\n",
      "\"bloo\" -> \"blood warm when thou well thou art, within thine own desert, as thou be not times in\"\n",
      "bloo\n",
      "\"bloo\" -> \"blood, that it could soy, but he powell min on juck permed it in thy part, to leave \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [\"the \", \"beau\", \"mothe\", \"bloo\"]\n",
    "\n",
    "for seed in seeds:\n",
    "  best = sequence_completion(seed, 80, True)\n",
    "  # print seed and text\n",
    "  print (f\"\\\"{seed}\\\" -> \\\"{best}\\\"\")\n",
    "  sampled = sequence_completion(seed, 80, False)\n",
    "  # print seed and text\n",
    "  print (f\"\\\"{seed}\\\" -> \\\"{sampled}\\\"\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1654727458204,
     "user": {
      "displayName": "段辉然",
      "userId": "04583225436557064813"
     },
     "user_tz": -120
    },
    "id": "Nt7lVljhQ7PW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL-Assignment10.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a29cabff5744fce69e08a959ab87b9e77a9f67b498d08783caa8c3bb16f23a00"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
