{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0BvDamecqTZ"
   },
   "source": [
    "Assignment 7: Transfer Learning\n",
    "===============================\n",
    "\n",
    "\n",
    "Microsoft Forms Document: https://forms.office.com/r/MvPiCwh6jR\n",
    "\n",
    "\n",
    "Here, we use parts of the Fruits and Vegetables dataset that can be downloaded from Kaggle: https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition\n",
    "\n",
    "For this small example, I have subselected some images, which are available here: https://seafile.ifi.uzh.ch/f/72e1d9c4ef20420eb1d9/?dl=1\n",
    "\n",
    "First, we need to download and extract all our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0PdPkkZcqTc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_zip_file = \"fruits.zip\"\n",
    "if not os.path.exists(dataset_zip_file):\n",
    "  import urllib.request\n",
    "  urllib.request.urlretrieve(\"https://seafile.ifi.uzh.ch/f/72e1d9c4ef20420eb1d9/?dl=1\", dataset_zip_file)\n",
    "  print (\"Downloaded datafile\", dataset_zip_file)\n",
    "  import zipfile\n",
    "  zipfile.ZipFile(dataset_zip_file).extractall() ### extractall()方法会将 zip 文件的所有内容提取到当前工作目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMUpExnxcqTd"
   },
   "source": [
    "Task 1: Data Transformation\n",
    "---------------------------\n",
    "\n",
    "We need to instantiate a proper `torchvision.transform` instance to create the same input structure as used for training our network.\n",
    "We need to combine 4 transforms, which can be compiled from the PyTorch website: https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "1. We need to resize the image such that the shorter side has size 256.\n",
    "2. We need to take the center crop of size $224\\times224$ from the image.\n",
    "3. We need to convert the image into a tensor (including pixel values scaling)\n",
    "4. We need to normalize the pixel values with mean $(0.485, 0.456, 0.406)$ and standard deviation $(0.229, 0.224, 0.225)\n",
    "\n",
    "Since we will use networks pre-trained on ImageNet, we need to perform the exact same transform as used for ImageNet testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Czs9EJNAcqTe"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.transforms import ToTensor\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "imagenet_transform = torchvision.transforms.Compose([ ### 这里要用Compose，且有一个[] !!!!!!\n",
    "    torchvision.transforms.Resize(256), ### 试试直接写Resize(256); 如果我写 ([256,256]) 也可以运行，但是会有一些小影响，比如acc会变？不知道具体有什么区别\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485,0.456,0.406),(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oRWAkj9cqTe"
   },
   "source": [
    "Task 2: Dataset Loading\n",
    "-----------------------\n",
    "\n",
    "We here use the `torchvision.datasets.ImageFolder` dataset interface for processing images. \n",
    "You can use its documented `is_valid_file` parameter to distinguish between training and test set.\n",
    "The training files are all called `gallery.jpg` while test files are called `probe.jpg`.\n",
    "\n",
    "Create two datasets, one for the training set, one for the test set. Use the transform defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qL02JEKkcqTe"
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.ImageFolder(\n",
    "  root = \"fruits\", \n",
    "  transform = imagenet_transform,\n",
    "  is_valid_file = lambda x : \"gallery\" in x  ### is_valid_file call-back function → Use to filter some files\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(\n",
    "  root = \"fruits\",\n",
    "  transform = imagenet_transform,\n",
    "  is_valid_file = lambda x : \"probe\" in x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnKel1yncqTf"
   },
   "source": [
    "Test 1: Data Size and Types\n",
    "---------------------------\n",
    "\n",
    "Check that all datasets contain the same number of images as classes.\n",
    "Check that all input images are `torch.tensor`s of size $3\\times224\\times224$ and of type `torch.float`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOFU2XurcqTg",
    "outputId": "76306fd5-b77b-412a-e133-b47584fdd201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(trainset): 14\n"
     ]
    }
   ],
   "source": [
    "assert(len(trainset) == len(testset))\n",
    "print(\"len(trainset):\",len(trainset))\n",
    "for x,t in trainset + testset:    ### 为啥这里可以直接用加号？？？\n",
    "  assert type(x) == torch.Tensor\n",
    "  assert x.shape == (3,224,224)\n",
    "  assert x.dtype == torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLRTK3PxcqTh"
   },
   "source": [
    "Task 3: Pre-trained Network\n",
    "---------------------------\n",
    "\n",
    "Instantiate a pre-trained network of type ResNet-18. \n",
    "Modify the network such that we extract the deep features from before the last fully-connected layer of the network.\n",
    "For your reference, the implementation of the `forward` function of ResNet networks (including ResNet-18) can be found here: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L264\n",
    "\n",
    "You can also check if other networks perform better, especially deeper ResNet topologies.\n",
    "Be aware that our strategy to remove the last fully-connected layer might not work in other network topologies, only in residual networks.\n",
    "\n",
    "Please Note: while we modify the `forward` function, we will still use the `__call__` function to extract our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPul4lU7cqTh",
    "outputId": "9c9f7e33-02bb-46c7-c99d-2feac85bb91a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,176,512\n",
      "Trainable params: 11,176,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 105.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# instantiate pre-trained resnet 18 network\n",
    "network = torchvision.models.resnet18(pretrained=True)\n",
    "network.eval() ### model 的 test 开关，例如 Dropouts Layers、BatchNorm Layers 等会进入评估模式\n",
    "from torchsummary import summary\n",
    "summary(network,(3,224,224))\n",
    "# make sure that deep features can be etxracted from the network\n",
    "  # network.children() -> resnet 的每一层\n",
    "  # network.children()[:-1] -> 去掉最后一层\n",
    "  # list( network.children()[:-1] ) -> 把他们的type变成 list\n",
    "  # *(list) 星号将 可迭代对象 扩展为 函数的参数列表 eg. a = [1,2,3] -> func(*a) == func(1,2,3)\n",
    "network = torch.nn.Sequential( *( list( network.children() )[:-1] ) )\n",
    "summary(network,(3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-iJWlQXcqTi"
   },
   "source": [
    "Task 4: Extract Features\n",
    "------------------------\n",
    "\n",
    "Implement a function that extracts all features for a given dataset.\n",
    "Store the results in a dictionary: `target : feature`.\n",
    "Extract the features for the training and the test set.\n",
    "\n",
    "实现一个函数，提取给定数据集的所有特征。将结果存储在一个字典中：目标：特征。提取训练集和测试集的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wj82D5gGcqTi"
   },
   "outputs": [],
   "source": [
    "def extract(network, dataset):\n",
    "  features = {}\n",
    "  with torch.no_grad(): # with torch.no_grad() 没有大的影响，但会运行更快一点\n",
    "    for x,t in dataset:\n",
    "      features[t] = network(x.unsqueeze(dim=0)) ### 模型接受4个参数 第一个是 batch-size 因为我们是逐个预测得，所以直接加一行啥都没有\n",
    "  return features\n",
    "\n",
    "train_features = extract(network,trainset)\n",
    "test_features = extract(network,testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b9Iq73-cqTi"
   },
   "source": [
    "Test 2: Check your Features\n",
    "---------------------------\n",
    "\n",
    "Check that all your features are of dimension 512 and of datatype `torch.float` (larger ResNet topologies might have 2048-dimensional features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2k-dWTjncqTj",
    "outputId": "56e0ad4b-9c93-468f-8043-cf25353eab1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# check features\n",
    "for v in train_features.values():\n",
    "  print(v.shape)\n",
    "  assert v.shape[1] == 512\n",
    "  assert v.dtype == torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AomVyHpocqTj"
   },
   "source": [
    "Task 5: Similarity Computation\n",
    "------------------------------\n",
    "\n",
    "Iterate over all samples in the test set.\n",
    "Compute the cosine similarities to all samples in the training set.\n",
    "Store the similarity values in a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OselsibOcqTj"
   },
   "outputs": [],
   "source": [
    "O = len(testset)\n",
    "similarities = torch.empty((O, O))\n",
    "# compute similarities\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.CosineSimilarity.html\n",
    "# >>> cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "# >>> output = cos(input1, input2)\n",
    "# dim (int, optional) – Dimension where cosine similarity is computed. Default: 1\n",
    "# eps (float, optional) – Small value to avoid division by zero. Default: 1e-8\n",
    "\n",
    "cos = torch.nn.CosineSimilarity() ###### 注意这里的CosineSimilarity()要带括号！！！\n",
    "for t, v in test_features.items():\n",
    "  for t2, v2 in train_features.items():\n",
    "    # similarities[t][t2] = torch.nn.CosineSimilarity()(v,v2)   ###### 这么写才对！！！！！\n",
    "    similarities[t][t2] = cos(v,v2)\n",
    "  # t = [0,1,2,3,4,5,6,7,8,9,10,11,12,13] 我也不知道这些 target 怎么来的，可能是dataset自动生成的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAS8cdWQcqTj"
   },
   "source": [
    "Task 6: Plot Similarity Values\n",
    "------------------------------\n",
    "\n",
    "Plot the similarity matrix as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "4IMBrZdWcqTk",
    "outputId": "0ff46e4c-d753-48ca-f056-8731fffb6460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Testing class')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAE4CAYAAADPf+9qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd7hdVZn/P9/0hBRAQhGBIFKkl4BUBUEdZ9QfIshIE3VEbMAwoKOiBh3HURkdAUUiYlAREeyNIl1qEhJCV+nSayBAQsr398daJzn35Nx79tn71pP38zz3uXuvvd611r7lPau867tkmyAIgk5k2EA3IAiCoK8IBxcEQccSDi4Igo4lHFwQBB1LOLggCDqWcHBBEHQsIwa6AZ3M6NXHety6E0rbL3lkVGlbj1BpW4Bhi5aVtn1lUrXPzdFPLCxtu3D90ZXqHvlCtZ/b8MmvlLZduGhkpbpZUr7tI8YuqVT1iGHl/14WvlLtvV+5/+GnbE9u9iwcXB8ybt0J7POD95S2f/aLG5W2fXlytT+aife+WNr2wbeWd+oAU75ze2nbOz+7eaW6X31FNec86aMPlra9855XV6p7xNPlf+erb/V0pbonr7agtO1dD6xXqe4H3v+ZB7p7FkPUIAg6lnBwQRB0LOHgekDSkZJOH+h2BEFQjnBwQRB0LB3r4CT9WtJsSbdLOiqnLZD0rZx2maTJOf1KSd+WNFfSbZJ2aVLeZEm/kDQzf+3R3+8UBEF7dKyDAz5oeydgKnCMpFcBqwGzbG8FXAV8sS7/ONvbAx8Dzm5S3reBb9neGXgPcFaftj4Igsp0cpjIMZLena83ADYFlgHn57SfAL+sy38egO2rJU2UtHpDefsBW0rLY40mShpvu8v6eO4tHgUwdp3xvfUuQRCUoCMdnKS9SQ5pN9svSboSGNMkq7u5bnY/DNjVdo9RqLanA9MB1thi7RDbC4IBpFOHqJOAZ7Nz2wLYNacPAw7M14cAf6mzORhA0p7AfNvzG8q8BPhk7UbS9n3R8CAIeo+O7MEBFwFHS7oTuBu4Iae/COwi6STgCbJTyyyUNAcYCXywSZnHAN+RNI/0c7saOLqP2h8EQS/QkQ7O9iLg7Y3pkrB9fDdmP7F9XEM5M4AZ+fopujrEIAgGOZ06RA2CIOjMHlx32G66rGl7735uShAE/UD04IIg6FhWqR5cf7Po6dHc9+NNy9t/4vnStotvL68lB/DEzquVttWSatEx89+yRWnbcQ8Nr1T3kjHV2v74z8pLXE0aVU2LbsGG5du+6Iq1KtV9/9jy9uMWV6q6R6IHFwRBxxIOLgiCjmXIOThJUyTdNtDtCIJg8DPkHFwQBEFRhqqDGyHpXEl3SrpQ0jhJX8gyRrdJmq68Kz5LIX1N0k2S/ippr5w+RdI1km7OX7vn9L2zzYWS7sr11MpqWkcQBIOToergNge+a/v1wPMkiaPTbe9se2tgLPCOuvwjbO8CHMcKiaQngLfY3pG0Q+HUuvw75LxbAq8FatpvPdURBMEgY6g6uIdsX5uvfwLsCewj6UZJtwJvBraqy1+TRZoNTMnXI4Hv5/wXkJxZjZts/8P2MmBunU1PdQBJLknSLEmzliwsfzJVEATVGapxcM2kjb4LTLX9kKRpdJVHWpS/L2XFO/878DiwHcnRL2ySf7mNpDEt6kgNqZNLGjd5g5BLCoIBZKj24DaUtFu+rpc9ekrSeFZIIvXEJODR3Es7HGgVIVpzZu3UEQTBADJUe3B3Ax+XdDZwB3AGsAZwG/AYMLNAGd8FfiHpCJK8Uo/jSdvPSfp+m3UEQTCADDkHZ/t+oNlenpPyV2P+veuunyLPp9n+G7BtXdZP5/QrgSvrbD5Rd920jiAIBidDdYgaBEHQknBwQRB0LOHggiDoWIbcHNxQQstg1AvlI0XW/FZ5yaOt/q/aGsjsr+xU2nb+xtU+NxdNKm8/ckHrPD0xbHG1yJ5hI8pvblm4ZqWqec3lS0rbqmJA0+M7jSxtO+nepdUq74HowQVB0LGEgwuCoGMJBxcEQccSDq4EkvaXtGXrnEEQDCTh4DKSRvR038D+dN2cHwTBIKQjV1Hz9qsTSJvw5wE/J+1AGAU8DRxq+/G8YX4TkiTSg5Lubrj/DHA2sBbwJPAB4DXAu4A3SToJeI/te/rx9YIgKEjHOThJW5Gc2e62n5K0JsnR7Wrbkv4N+BTwH9lkS2BP2y9nh1d//zvgHNvnSPogcKrt/SX9Fvi97Qv7+/2CIChOxzk4kk7bBXnfKbafkbQNcL6k9Ui9uPvq8v/W9svd3O8GHJCvfwx8vVXlko4CjgIYNW6NSi8SBEE1VpU5uNNIarzbAB+hq45bo4pIJZVK29NtT7U9dcSY8meLBkFQnU50cJcDB0l6FUAeok4CHs7P399GWdcB/5qvDwWuydcvABOqNzUIgr6k4xyc7duBrwBXSboF+CYwDbhA0mzgqTaK+yTwAUnzSKKYx+b0nwEnSpojaZNea3wQBL1KJ87BYfsc4JyG5N80yTetxf0DpDm9RrtriTCRIBj0dFwPLgiCoEY4uCAIOpZwcEEQdCwdOQc3WBix4BXWvO7h1hm7YdHGk0vbzv38DqVtAaaddlZp2//4v49UqnvtC+8obbtwl00r1f3iuuV1zQDWunl+adtntp1Uqe5xDz5f2tbDy+vYAUxaY/XSthP/cGulunsienBBEHQs4eCCIOhYwsEFQdCxhIMLgqBjCQdXgBbacEEQDFJWuX/cJlpxn6dB8832g5JmAAuBHYBr857W54GpwLrAp0IuKQgGN6uUg+tGK+4cGjTfSIq9kMQtd7e9NDu89YA9gS2A3wIrObh6uaQxw2M/fhAMJKvaEHUlrTiS5ttP8/MfkxxYjQts1x/a+Gvby2zfAazTrIJ6uaRRw8f2/hsEQVCYVc3BtUujNtyiuutqkZFBEPQ5q5qDa6YV153mWxAEQ5xVag7O9u2SalpxS4E5JM23H0o6kRUHywRB0AGsUg4OutWKa6b5dmSL+/G93bYgCHqXVW2IGgTBKkQ4uCAIOhbZHug2dCyjN36N1/3iJ0vbj79rVGlbLW2dpydGP1P+72LmV86oVPcexx1d2vaRNy+rVPe4B6vN2px4RPnY71NmHFip7le2X1DadvEzY1pn6oEJr36htO3SpdX6WXcdcPJs21ObPYseXBAEHUs4uCAIOpZwcEEQdCzh4Jog6UhJp+fro/MG/SAIhhirXBxcKxqlkWx/b6DaEgRBNTrWwUn6PHAYaXfCQ8BsYD5J6WMU8HfgcNsvNUojkWSUauVMAxbYPkXS64DvAZOBpcBBtu/pr3cKgqA9OnKIKmln4D3AdsDbSRpuAL+0vbPt7YA7gQ/VmdWkkY7voehzge9k+92BR3u98UEQ9Bqd2oPbA/iN7YXAQkm/y+lbS/ovYHVgPHBxnU2jNFIXJE0A1rf9K4BcdrN8y/Xghr+q/FFqQRBUpyN7cD0wA/iE7W2Ak4H66MZGaaRS1OvBDZ+wWm8UGQRBSTrVwV0LvFPSGEnjgXfk9AnAo5JGkqSRCmP7BeAfkvYHkDRa0rjebHQQBL1LRzo42zNJkuLzgD8Bt5IWGD4P3EhygHeVKPpw4BhJ80g6cuv2SoODIOgTOnUODuAU29NyL+tqYLbtm4GVNko2kUKaQRrOYntaXfrfaCKtFATB4KSTHdx0SVuS5tnOyc4tCIJViI51cLYPGeg2BEEwsHTkHFwQBAF0cA9uMDDsZTHh9gqabhWkzcY+WU0Xbc0bHi9tu8nPy+u5AXiP8rbj/17tT/qVNarpI5585f6tM3XD2Ir/jb6/fFiS1lvUOlMPjP1F+ZjPZ7auVHWPtOzBSTooB7ki6SRJv5S0Y981KQiCoHcoMkT9vO0XJO0J7Af8gCYrkUEQBIONIg6utn3pX4Dptv9A2qweBEEwqCni4B6WdCZwMPBHSaML2g04kr4kab+BbkcQBANDkWnN9wL/RAqcfU7SesCJfdus3sH2F/q6DknDe9qkHwTBwFGkJ7Ye8Afbf5O0N3AQcFOftqoEkj4v6W5Jf5F0nqQTJM2QdGB+fr+kkyXdLOlWSVvk9MmSLpV0u6SzJD0gaa387DBJN0maK+lMScNz+gJJ/yvpFmC3AXvpIAh6pIiD+wWwNIs9Tgc2AH7ap61qkx703xp5yvaOpEWSE3LaF4HLbW8FXAhsmMt8PWlYvoft7UlzkbUN+qsBN9rezvZf+uCVgiDoBYoMUZfZXiLpAOA026dJmtPXDWuT7vTfGvll/j4bOCBf7wm8G8D2RZKezen7AjsBMyUBjAWeyM+Wkhz/StTrwY2csEbZ9wmCoBco4uAWS3ofcATwzpw2su+a1KfUohmX0vrdRdrD+pkmzxZ2N+9mezqpp8vYdTeIU7WDYAApMkT9AGme6Su275O0MfDjvm1W23Sn/1bU9r0Akt4K1LpdlwEHSlo7P1tT0ka92OYgCPqYlj0423cAx9Td3wd8rS8b1S62Z0qq6b89zgr9tyKcDJwn6XDgeuAx4AXbT0k6CbhE0jBgMfBx4IFef4EgCPqElg5O0qbAV4Ga9BAAtl/bh+0qQzP9t+/XHtqeUnc9C9g7384H3pbnGXcDdra9KOc7Hzi/sSLb4/vsLYIg6DWKzMH9kLTS+C1gH9KQdTAG+pbVf9sQ+Hnupb0CfLivGhgEQf9SxMGNtX2ZJNl+AJgmaTbQ50G07VBW/y2r9O7Qy80JgmAQUMTBLcq9m79J+gTwMOnIvaAFWgbDXy5vv9at5Y1HPvpc+YqBpWuW/xWPWKBKdb/ujPLTnAvPqaY5NPIzkyrZP7z3hPJ1v1Bt0X3sk+Vtx9xcbXv58xuV/52vPavaRqB7e3hWZKh5LDCOtNCwE+nglfdXalEQBEE/UGQVdWa+XECafwuCIBgSdOvg8m6AbvvMtt/VJy0KgiDoJXrqwZ3Sb60YACRNAX5ve+u6tKnAEbaP6c6uTN4gCAaGbh2c7asAJK0GvGx7Wb4fDozun+b1Lzk+blZv5w2CYGAosshwGWmRocZY4M9905yBQdJrJc2RdKKk3+e0WyWtrsTTko7I6T+S9BZJe9fyBkEwOCni4MbYXlC7ydfjesg/pJC0OUkZ5EhgZt2ja0kqJVuRVqL3yum7Adf1YxODIChJEQf3Yv0pWpJ2AipEdw0qJgO/AQ61fUvDs2uAN+avM4BtJK0PPGv7xe4KlHSUpFmSZi15udtsQRD0A0Uc3HHABZKukfQX0t7MT/Rts/qN+cCDJE24Rq4m9dr2Aq4EngQOJDm+brE93fZU21NHjC1/TmUQBNUpFAeX5b03z0l3217ct83qN14hiV1eLGkB8Ejtge2HsnT5KNv3Zud+Ap3j3IOg4ym0ad72Ytu35a9OcW4A5OHmO4B/ByY2PL4R+Gu+vgZYHwiJ8iAYIlTbuDeEsX0/sHW+fg7YOT/6bV2ew+uur6PuA8H2laShaxAEg5TBKHsUBEHQKxQRvNyxSfJ84AHbS3q/SUEQBL1DkSHqd4EdSXLgIg3rbgcmSfqo7Uv6sH1BEASlKeLgHgE+ZPt2gKya+yXgU6Rj+MLBdcPSMTB/82Wl7RdMGdM6Uzesc9PapW0BFo8tP3sxsqIe3JIN1ipt++gV1aQK3zm9Wgz33TN3bp2pG/76L9+rVPcWF3y8tO12O95Tqe4nrntdadsl44ZXqrsnivwVb1ZzbrD8EJotbPekMxcEQTDgFOnB3S7pDOBn+f5g4A5Jo0knTQVBEAxKivTgjgT+TtrRcBxpX+aRJOe2T181LAiCoCpFdjK8DPxv/mpkQZO0AUHSgjjOLwiCeoqEiewBTAM2qs8/CM9FDYIg6EKRIeoPgG+SNqTvXPc1aMm6bjMlzZN0ck6bIukuSTMk/VXSuZL2k3StpL9J2iXnW1PSr7PtDZK2zenTJJ0t6UpJ90oKJd8gGOQUcXDzbf/J9hO2n6599XnLSiLprcCmwC7A9sBOkt6YH7+ONNTeIn8dQnLcJwCfzXlOBubY3jan/aiu+C2At+WyvyhpZN++TRAEVSiyinqFpG+QYt4W1RLbODm+v3lr/pqT78eTHN6DwH22bwWQdDtwmW1LuhWYkvPvCbwHwPblkl4lqbYJ/w+2F5HOin0CWAf4R33lko4CjgIYvsYaffOGQRAUooiDe0P+PrUuzcCbe785vYKAr9o+s0tiOmRmUV3Ssrr7ZRQ8BLvuemkzG9vTgekAozfcoNpJvkEQVKLIKupQCwW5GPiypHNtL8gqvO3E610DHJrL2Bt4yvbzUrXo/CAI+p+ezkU9zPZPJB3f7Lntb/Zds8pj+xJJrweuz05pAXAYqcdVhGnA2ZLmAS8B7++LdgZB0Pf01IOr6W1PaPJs0A296mPgbH8b+HaTbFvX5Tmy7vp+VmjDPQPs36T8aQ33WzfmCYJgcNHTuai1Oaw/2762/lmOjQuCIBjUFAkTOa1gWhAEwaCipzm43YDdgckN83ATgb7TNwmCIOglepqDG0WKIRtB13m450nH5wUt0MhljFqv/NmoE/5Ufmvt01tV+wza6LfzS9ue9qUZler+9JyPlrZdPLHa9PCfz9itkv1Zn55e2vYNX652YNvwN71U2vauSzetVPeGb/pH60zdsGhJ3x0N09Mc3FXAVZJm2H4AQNIwYLzt5/usRUEQBL1EkTm4r0qaKGk14DaSFtyJfdyuIAiCyhRxcFvmHtv+wJ+AjYHDezYZWkj6kqT9BrodQRD0LkUGvyPzpvL9gdNtL5Y06OLgqmD7CwPdhiAIep8iPbgzgftJgb9XS9qItNAwqJF0vKTb8tdxWS7pTknfl3S7pEskjc15Z0g6MF/vK2mOpFuzPNLonH6/pJMl3ZyfbTGQ7xcEQWtaOjjbp9pe3/Y/O/EAg1yqXNJOwAdIQgG7Ah8G1iCpinzH9lbAc2TVkDq7McAM4GDb25B6uPVLek/Z3hE4gySxFATBIKalg5O0jqQfSPpTvt+Swb8/c0/gV7ZftL2AJPW0F0kuaW7OM5sVEkk1Ns95/prvzwHeWPf8lz3YAkkuSdIsSbOWPl8+RCQIguoUGaLOICl0vDrf/5V0+MxQpKXcUUH7bm1tT7c91fbU4RNXa5YlCIJ+olsHJ6n2D7yW7Z+TNNOwvYTiyhwDxTXA/pLG5fCWd+e0VtwNTJFUO8X2cOCqPmpjEAR9TE89uJvy9xclvYqsICJpV6B8mHs/kNWGZ5De4UbgLODZAnYLSXN3F2SV32VAtePGgyAYMHoaotUUHo8HfgtsIulaYDJDYKtW1qtr1Kyrl0s6pe76yLrry4AdmpQ3pe56FrB3rzU2CII+oScHV7/J/lfAH0lObxGwHzCvj9sWBEFQiZ4c3HDSZvtGre5xfdecIAiC3qMnB/eo7S/1W0uCIAh6mSJzcEFJ9NIwhs9ppvhejOGLl5W2Xf2v1XbTvTilvFTTkWcfW6nuKfc+Vtp29PbrVqp7zAHl6wb4t0s+VNr29BN+WKnuL087srTti+tVqpqHr1u/tO3qd/fdzs+eVlH37bNagyAI+oFuHVw+fCUIgmDIUmQnQxAEwZAkHFwQBB1Lxzo4JTr2/YIgaM2QdgDdaL7dLelHJHn1DSSdkdU9bpd0cp1tU303SZMlXZrznyXpAUlr5WeHSbpJ0lxJZ0qK08WCYBAzZB1cC82379reKmvXfc72VGBb4E2Stq0rppm+2xeBy7Nm3IXAhrm+1wMHA3vY3p4kOHBoH79mEAQV6Lvzuvqe5ZpvAJJqmm8P2L6hLt97JR1Fetf1gC1Zsc2sXt/tgLpy3w1g+yJJtU36+wI7ATMlAYwFnmhsVK7rKIARE9eo/pZBEJRmKDu47liuMilpY1LPbGfbz0qaAYypy9tS360OAefY/kxPmWxPB6YDjF1vg446uyIIhhpDdohKMc23iSSHN1/SOsDbC5R7LfBeAElvJQ17AS4DDpS0dn62Zj6fIgiCQcqQ7cHZvjn3yGq6dStpvtm+RdIc4C7gIZLzasXJwHmSDgeuBx4DXrD9lKSTgEvy6uxi4OPAA73xPkEQ9D5D1sFBa823nOfIbmyn1F3X67vNB95me4mk3UjD20U53/nA+b3R9iAI+p4h7eD6iA2Bn+de2iuk1dkgCIYg4eAasP03mij6BkEw9BjKiwxBEAQ9Ej24PmTZ2GUs2ual0vYvbVZ+o8SaN4wqbQsw7onFpW1fXq9adMz8HdYubbt4fLW6n5y7TiV71lhS2vSY3x1Zqep/OW52advf3bpt60w9MH71l0vbPrFmec1EAH7S/aPowQVB0LGEgwuCoGMJBxcEQccSDq4ikmIeMwgGKauUg8tySndJOlfSnZIuzFu9dpJ0laTZki6WtF7O/2FJMyXdIukXksbl9BmSvifpRuDrA/pSQRB0yyrl4DKbk+SUXg88T9pudRpwoO2dgLOBr+S8v7S9s+3tgDuB+iOTXgPsbvt4giAYlKyKw6uHbNf2pP4E+Cxpe9elWQZpOPBofr61pP8CVicdgn1xXTkX2F7aWHi9XNLwtSb1yQsEQVCMVdHBNQZKvQDcbnu3JnlnAPvnTftHsmK/KtTJMnUpvE4uafRr1w+5pCAYQFbFIeqGeRM9wCHADcDkWpqkkZK2ys8nAI9KGkmo9wbBkGNVdHB3Ax+XdCdJ6+004EDga5JuAeYCu+e8nwduJMks3TUAbQ2CoAKr4hB1ie3DGtLmAm9szGj7DNJ5DY3pR/ZN04Ig6E1WxR5cEASrCKtUD872/TQIYgZB0LlEDy4Igo5llerB9TejnhHrn1detmjcgy+Utl12S3npHIDhm21S2nb0k9Ukh7RspfDCwkyeWy0yZ/Sz5eWOAB78pwq/70dVqe7ZX9uxtO3w/V+pVPc63x7TOlM3DFu8qHWmHujpUJTowQVB0LGEgwuCoGMJBxcEQceySjo4ScfVlEF6I18QBIOTVdLBAccBRRxX0XxBEAxCOsLB9aDztq+kOZJulXS2pNGSjgFeDVwh6Ypsf4akWZJul3RyTmuW7325rNskfW2g3jcIgmJ0hIPLNOq8HU9SAznY9jakkJiP2j4VeATYx/Y+2fZztqcC2wJvkrRtYz5Jrwa+BrwZ2B7YWdL+/fh+QRC0SSc5uEadt32B+2z/NaedQ5P9ppn3SroZmANsBWzZJM/OwJW2n7S9BDi3WXmSjsq9wVmLX2mqqBQEQT/RSQ6uMcLzuSJGkjYGTgD2tb0t8AegdNSi7em2p9qeOnLUamWLCYKgF+gkB9eo8zYLmCLpdTntcOCqfP0CSesNYCJJvHK+pHWAt9eVWZ/vJtLwdS1Jw4H31ZUXBMEgpJO2atV03s4G7gCOIYlZXpBPvpoJfC/nnQ5cJOmRPL82h6T39hBJ+41u8v0ncAUg4A+2f9MvbxYEQSk6ycE103m7DNihMaPt00hCl7X7I5sV2CTfecB5vdHYIAj6nk4aogZBEHShI3pwofMWBEEzogcXBEHH0hE9uMHKyPUWsf5//q20/X3f2by07fP/vHvrTD0wee7iSvZVmDjvqdK29x1STYtu2KLhleyXTCivJ/fy0mp1P7/lstK2Ix4qr+cGcNIPzixte/TsigfW/aX7R9GDC4KgYwkHFwRBxzIkHZyk1SV9rI/r2FtStXFeEAQDypB0cMDqQJ86OGBvVhwAHQTBEGSoLjL8D7CJpLnApTnt7aT9qP9l+3xJewMnk/akbgP8HLgVOBYYC+xv+x5J7wROAkYBTwOH5udHA0slHQZ8krTL4WxgLeBJ4AO2H+yHdw2CoCRDtQf3n8A9trcnbcfaHtgO2A/4hqT1cr7tSI7q9aS9qJvZ3gU4i+S0IK3B7Gp7B+BnwKdyXN33gG/Z3t72NaQdDefkDfnnAqf2/WsGQVCFodqDq2dP4DzbS4HHJV1FkjZ6Hphp+1EASfcAl2SbW4GaFtxrgPOzUxwF3NdNPbsBB+TrHwNfb5ZJ0lHAUQDj1hlf4bWCIKjKUO3BFaX+wMVldffLWOHcTwNOz6KYH6GCVBJ0lUsavUa12KIgCKoxVB1cvYzRNcDBkoZLmkwSobypjbImAQ/n6/d3UwfAdcC/5utDc71BEAxihqSDs/00cK2k20hDx3nALcDlpDm0x9oobhpJUmk2UB9C/zvg3ZLmStqLNGf3AUnzSPN5x1Z/kyAI+pIhOwdn+5CGpBMbnl8JXFl3v3ezZ1nTbSVdtyx1vm1D8ptLNzgIgn5nSPbggiAIihAOLgiCjiUcXBAEHcuQnYMbCrz0yihm/2OD0vaTRqm07ajnS5sCMPbqO0rbLntj49Rlezy70+TStiMWVKqaYUur2TOs8XC34ox8vvzvG2DpmPJyS0tXKy+1BPCBqz5Y2vaUPX9eqe739vAsenBBEHQs4eCCIOhYwsEFQdCxDDoHJ+k4SeMGoN6KszdBEAw2Bp2DA44D2nJw+aT5IAiCLvSZg5N0oqRj8vW3JF2er98s6VxJZ0iaJel2SSfnZ8cArwaukHRFTnurpOsl3SzpAknjc/r9kr4m6WbgoHz/1by1apakHSVdLOkeSUc3tGumpHm1ehvaLUnfkHSbpFslHZzT95Z0paQLJd2V36HaslcQBH1KX/bgrgH2ytdTgfGSRua0q4HP2Z5K2g71Jknb2j4VeATYx/Y+ktYiiVHuZ3tHYBZwfF0dT9ve0fbP8v2DWSPuGmAGcCCwK0n4EklvBTYFdiFpyO0k6Y0N7T6A7vXldiD1MLcEXgvsUeUHFARB39KXcXCzSQ5kIkmm6GaSo9sLOAZ4b9ZOGwGsR3Ia8xrK2DWnX5s7S6OA6+uen9+Q/7f5+63AeNsvAC9IWiRpdeCt+WtOzjee5PCuriujJ325m2z/AyCrCU+h4dCyej24EWtN6vknFARBn9JnDs72Ykn3AUeSpIbmkUQmXwe8DJwA7Gz7WUkzaK7DJuBS2+/rppoXG+7r9d4ateBG5PK+arvsIY71ZS6lyc/P9nRgOsCYTdYvH/UZBEFl+nqR4RqSI7s6Xx9N6j1NJDmn+ZLWIZ2nUKNeh+0GYA9JrwOQtJqkzSq052Lgg3XzeOtLWrtJm6voywVBMEjo661a1wCfA663/aKkhcA1tm+RNAe4i3SYy7V1NppsCgAAABY8SURBVNOBiyQ9kufhjgTOkzQ6Pz8J+GuZxti+RNLrgevzkHcBcBjwRF22X5E05m4hHWLzKduPSdqiTJ1BEAwcfergbF8GjKy736zu+shubE4jyYjX7i8nzYE15pvS3b3tGaRFhmbPvg18u0l54/N3k7TlWunLfaJZ+4MgGDwMxji4IAiCXiEcXBAEHUs4uCAIOhalKaegL5D0JPBAD1nWoutBN+1SxT7qXrXqrmo/mOveyHZTEcFwcAOIpFl5N0e/20fdq1bdVe2Hat0xRA2CoGMJBxcEQccSDm5gmT6A9lH3qlV3VfshWXfMwQVB0LFEDy4Igo4lHFwQBB1LOLgBYoDOndi4SNpgQtIwSbsPdDuGGlkN55SBbsdAE3Nw/Uz+Zz2LJMi5oaTtgI/Y/lgbZfwLsBV1Gnq2v1TA7uasjFyfNtv2ToVfoCTZkT5qe2G+HwusY/v+ArZzbO9Qos7/s32cpN+RlGG6YPtdbZQ1HFiHOoEK2w8WsNuMJNywUYPtmwvYCjgUeK3tL0naEFjXdiH5Lkk32N61SN4eyngXSTIM4Crbvyto9xqSaMaepJ/9NcCxNcHYgmXsThKVrf+5/aioPcTJ9gPBt4C3kdWHs3RUo2x6t0j6HulQnn1IjvJAWujVZamnrYBJkg6oezSR5kKjzco4APgasDZJOFSp+Z5YsOkXAPU9saU5bSWlmCZcJuk9wC/d3ifyj/P3Sj0ZSZ8Evgg8ThJPhfRPu20B8wuA7wHfJ71zO3w31/dm4EskrcRfUOxnBjBH0m9zG5aLw9r+ZRFjSV8lyfufm5OOkbSb7c8WMP8h8FPgoHx/WE57S8G6fwxsAsxlxc/NQFsOLnpw/YykG22/ob5XIukW29sVtJ9ne9u67+OBP9neqweb/wfsD7yLFbLukP5hfmb7ugL1/h14p+07i7Szif3cfF5GfVqh95b0ArAa6Q/9Zdp0rpL2Ba6z/XL7LV/+7m+w/XQJ29I95FqPu8Lfyg+bJNv2BwvazwO2t70s3w8H5thu6di7+X2vlNaD/Z3Alm1+oK1E9OD6n4dy19v5EJ5jgXacRu2f9CVJrwaeJp1p0S22fwP8Jn/6Xt9T3h54vKxzyzwp6V22fwvLnW6hvYm2J7TO1SNHAGdIeoY0VLoa+IvtZwvaPwTML1n37yR9jCSkulzy3vYzBWwXZ6digKwwvaxnkxXY/kCbbW3G6kCtre0cMvK0pMOA8/L9+0h/q0W5DVgXeLQNm5UIB9f/HE0S3FwfeBi4BPh4G/a/zwfofIN0kI9JQ9UiPCTpV6w4DaydeZFZks4Hfk3Xf9RCwx3Se58r6XRSD+whkuNpSd1c1Ma2vyxpA2C9onNRtt+fy3k1aUj/HdLxlEX//u8FrpT0B7q++zcL2L4/f68XUDXpVLZWnEpyjGtL+gqp7ScVajEgaQzwIVaery3UgwO+ShrmXkH6nb0R+ExB2w+S5uC+RXrf60jnsxRlLeAOSTfR9WdeeN4UYog6pMky7mNsF+pdSLqUNC9Sm5s6DDjUdst5karDnbpyasrJC9qwOYM8F2X79ZLWAC6xXWguKvck9gK2IfUa/0KSzi/Um5X0xWbptlc6V7e3yfOn+5IczGXt9KIlXUA6FuAQ0hzeocCdto9to4z1WDHnd5Ptxwra7WH72lZpPdi/qVm67auK2C8vJxxc/yDpNJqs5NWwfUwbZZVaXWo2f1NkXiQPk75m+4SibayzPcz2TyQd3+x5kV5QL8xFPQXcQ5rsv6LIym035ZRxziOBj7JiJfJK4EzbiwvYrtkk+YUittl+ju0d6uZrR5Ice6GVVUmX2d63VVo3ts1W7FdKa1HGOnR1rk/0lL8ZMUTtP2b1RiEVV5eeKjMvYnuppLKHXK+Wv1eZR6s6F7WWpK1ITuYrkjYF7rZ9eBF7SVuTer1r5vungCNs317A/AzSuSTfzfeH57R/K2B7M7AB8CypB7c68Jikx4EP257dwr7mCJ/L7/AYaRW8R/LQdhywVu4tKz+aSJpa6cl2N9Jq+eSGD7WJwPBWddeV817SNMyVuf7TJJ1o+8KiZUA4uH7D9jn190oHYtvpcOp2mEr51aVm8yJFJ6Lnlgk5cD6DtuJwrupc1ERgQ1Is2hTSZHlhB0na7H287StyeXuTwj6KBCDv3NDTvFzSLQXrvRS40PbFud63Au8hhVt8F3hDq3ZnB/V50ur5eOALBer9CHAcaZ5yNisc3PPA6S1sR+V6RtD1Q+150u+tKJ8j/eyegOUfan8G2nJwMUTtZyRNJf2BTiD94TwHfLDAp3HN/gLgGNttrS7lHtCPbB/aZpNr9qXm4CSd2tPzokPzinNR80jzbn8Brm4n2DTbNxvaFw1xuRk4yPY9+f61JKfVcqgm6Vbb2zSk1YabhUMuyiLpk06n3JWx3ch2T2rWrey7vLukYcAtjT+PVkQPrv85G/iY7WsAJO1JcnhFgkah5OpSHmZuJGmU7VfabXSFkINCjrsn8lzUE6wYWiNpZNG5qCJxWy24V9Ln6bo4c29B2xOBKyTdS3LOG1G81/yopE8DP8v3BwOP5w+rlj3QPIf138Crbb9d0pbAbrZ/UKRy26floe2WdF2FLTId8pKkb7DyCm7LHRyZiyRdzIrf+cHAHwvaLid6cP2Mmmw7amfytcrqkqQfAa8nDVfqh5lFJvprW2/aDjGpskiR7e+nyVwUaWdBt3NR6qWtWnmYdzJp2xGkd59WNI4ur3Zvnm/vtr2op/x1dmuRdlDU6r02t2M+sKHtv7ew/xPpw/NztreTNIIUqFuoF5RXj/cmObg/Am8nxQ+2HGpKugQ4HziBFCL0fuBJ258uUncu4z3U/b3Z/lVR2+VlhIPrXyT9HzCW9Mlk0ifTQuAnALZv7sO6S4c7VAkxyfbX296taFsbbL9P93NR37bddC5K0k62Z0s6AZjZ8HiC7d+XaU/BNr/Z9uXqujVuOW3ED1Zpw0zbOzesPrezm+BWYDuSU9wu9wh/UjCsaLbtnWpD6vr2VHiltokhav9Tm7dpdDY7kBxej114SbuSelKvJ03oDgdedIttS7kXtVnZOThgsu36ebgZko5rw77UIkVmV9sfrrO5RNIptj+Se0dNqevZHQJcZPs2AEnvI02iF3Jwed70s6wcmtPT0PdNwOXAO5s1DWj53kob9U9oUm/RYd6Lkl7FitXnXWlvR8bLtpdJWpIXap4g9aSLUJs+eFRJHOIR8ip0Tyhty2vW62p37zMQDq7fsb1PxSJOB/6V5CimknYDbFag3kpzcFTfejMm56//5yz0j07FuSjS6t2Fkg4hBfweAby1aMNJm81PBG4tWB+2v5i/V9kuVduofxbtb9QHOJ40HfFaSdcCk2lvJXOW0q6Z75PmUhcARbf6/ZekScB/kD6QJwL/3srI1bfldSGGqP1M/kStzauYtLL3JRfcyK18hFpD17+QnFDFObiNSH+ou7EixOSTth8q0u4qVJ2LymVsRtpm9iDwbrex8V7SX2zv2TpnU9vRpOH0FLr2worIW1WSssrxbJ8gqde8QHJOpzlLVrVZ1hRgou15ZdtTos49gU1t/zD/DUywfV9bZYSD61/yXNbV5Dk30vaZvW3vV9D+amA/0qf6Y6TNyEcWDFmoMgd3DnBcbWI9r2ye0ipMpM6+6r7ItslzSPV/4GuTnOKiXHeh1VUlNZL3AZfR5j5cSRflOmdT1wuz/b8FbKeRhoVlNuoj6eek+LOa3NEhwOq2D+reqot9lZ0MGwOfZGXHXnRh54ukEcrmtjdT2kd8ge22As7DwfUzkm6zvXVD2krxTj3Yb0RaPRxF6vJPAr5bpBdThW5WfwsLUarCvsiyc1H5Z9UtReO0JP0E2AK4nTo9uCLOudnvuyiSmvVWbLvIRn0k3WF7y1ZpTexqOxmuIK2i1u9kuMj2FgXqvgX4AQ3D+iKr/dl+Lmle+ua6BZJ5RT+UasQcXP9ziaR/BX6e7w8ELi5qXPdPuZA0TCuMUjT4pygXmzRM0hoNPbh2/n5eZ/sgSf/P9jmSfkoKtyhCqbmoog6sADvb3rx1tqZcJ2kb27e2a2i7qpz8zZJ2tX0DgKQ3UGzLYP1OhvpV/SI7GWostN1jkHcLXrFtSbUFktVaGTQjenD9jLqKN0JeBc3XLVeJlPaETmNlCeyWn+pVYpMkHUFaSbwgJx0EfMX2j7u36mJ/k+1d8hD7Y6Th9U0F290vsuo91P9D4Bu27yhhewewKSkweBErVgOLDo/LBtqiJBq5OWneEdJ2tbuBJUXaoGo7GQ4hvfcldB1eFwqDyqE9m5IUgL9K2mb403bbEw5uAMi9n03p+kdbtOt+F2lo2jin03KRompsklIkfK23d3k7//CS/o0kt70NMIO0X/HzzntVW9hOo8JcVFWyo9gEuI82nVQeJq9BWr2FNP/6XJHepSoE2tbV3S2t2iBpFOmDsIwSyldJwgL30HVYXzTEBUlvIa12C7jY9qVFbZeXEQ6uf8n/6McCryEpguxKktNuOXGb7W90N4GtBWxvsL2r0haYU0mxSRfa3qRMeW3W/R+smPCvzek8B8y2PbeFbaW5qKp05ygKOqljScohvyS99/7A94v0RKoE2vYGks4iKaHUhCIOB5babqmEoiTzvmXJkKT6cibSdaTS1odazMH1P8eSNK5usL2P0iby/27D/gqlPX6/pP2uf7PYpHaCdauwE2lVrHYq0zuAecDRki6w/fXuDHthLqoSth9oCFmYTOqBFuFDpEDlFwEkfY0crlHAtkqgbW9QRQnlNtKWurY13AAkfYQ0x7yQ1AMUxZWQlxMOrv9ZaHuhJCSNtn2XpHYmsGu9t6l1aS13QGQOIg1xbgP2qYV6sMLp9CWvAXZ0FovMw68/kIY/s4GVHJwGwXan3I7lIQuk7WEjSWE+RUIWRNeFkaWs6MG2okqgbW+wVNIm7qqEUnSRZ3XgLkkzKSc5fgKwte1C53Z0Rzi4/ucf+Y/218Clkp4FCq/2udpOiG1tP1dX1jOS2j5vtCRrU/eHTtrKs47tlyV1t/m8fruTWfEpXvveLw4OeDc5ZAHA9iOSikbc/xC4UeksDEhD1JZqHpIEfDX/vr6X4+n6NdCWrkookMJ0iu7MaBpz2Qb3AC9VLCMcXH9j+935cprSYR6TgIvaKUMlD36meqhHFc4l/aP/Jt+/E/hpXv5vuljhvN2JNNypOTby9XxJ27eav+slSocs2P6mpCtZsQvjA7bnFLCzpD+SFmVwSZn1ilwLnEnS4XuOFM5UqAdp+ypVkxz/DCnE5ka69gALS/tDLDIMOdTNwc+2P1TAtlKoR1WUNq3XhnXX2i4k455j5qaStpiJFfN3U0jR7d3O3/UGvRWyUKLec4DTbTcqofQLqrATQitLju8FFJYcV9I7/AsrBwqf061Rs3LCwQ0tVOLg5wb70qEeA0WOnfvnuvm78aT5u38ircL2GJnfS22oHLJQos67SI71flKsZFsxdL1Qf6mdEDnfLcBb3CA57uIHBRXeJdMTMUQderR98HM92aENeqfWQJn5u14lO7Q+d2oNvI0mMXT9WH/ZnRAAwxqGpE8Dw9qo+0+SjiItgJWOfQwHN/SoHfz8dVbIgRc9+Hmo0vb8XW+gXtYmK8H+dI2h+zFpRbVPh8Z17ESaB+uyEyLH57XqSf5J1STH35e/1x803XaYSAxRhxiSxpLO2dyL9Au/BjjDJSRwhhJl5++GMkqH5exWF0O3GnB9Pw5RS++EyPF+N9JV5n3XgtsCh5EO6jm/jeY2Lysc3NAiT/y+wAq5pUOASbbfO3CtCvqC3FPaufbhpaTyMdNtniw1EKj5wc+F1UCUdQ+rtiOGqEOPrRsmea9Q2tAddB6lYugGEkkfJYkpvDb3QGtMIIWdFOXPefX6fLqKs7Y1Bxc9uCGGkjbZ6Q0Tvx+3fcTAtizoCyTtSN0wr0gM3UCStwKuQQqn+c+6Ry+045x6a/9xOLghglao045khQSOSbJJd/VHqEQQDDXCwQ0RqkrfBMFQQtI40qE5G9o+StKmJPnyto56DAcXBMGgQ9L5pDCoI2xvnR3edS54pmuNdgLvgiAI+otN8ha8xQC2X6K4CstywsEFQTAYeSXHfNYEDjah626WQkSYSBAEg5FpJJWdDSSdSwrybvsQ7ZiDC4JgUKJ0SPqupKHpDWXEL8PBBUEw6FCFQ6friSFqEASDBq04dHotSWtAl0On12+3vHBwQRAMJuoPnZ7NCgfXzqHTy4khahAEgw5VOHS6Sznh4IIgGIxI2pp06HX92SM/aquMcHBBEAw28lGNe5Mc3B+Bt5OOvDywnXIi0DcIgsHIgaTTvB6z/QFgO9IJdG0RDi4IgsHIQtvLgCWSJgJPABu0W0isogZBMBiZmc8e+T5pNXUBBc9krSfm4IIgGHRkYderSGc5LAQm2p7Xs1WTcsLBBUEw2JC0D+lgpb2ATYA5wNW2v91WOeHggiAYjEgaDuwM7AMcDbxse4t2yog5uCAIBh2SLgNWI827XUM6XeyJnq1WJlZRgyAYjMwDXgG2BrYFts76cG0RQ9QgCAYtkiYARwInAOvaHt2OfQxRgyAYdEj6BGmBYSfgfuBs0lC1LcLBBUEwGBkDfBOYbXtJ2UJiiBoEQccSiwxBEHQs4eCCIOhYwsEFgwJJr5I0N389JunhuvtRLWynSjq1QB3X9V6Lm5Z/paSpfVlH0B6xyBAMCmw/DWwPIGkasMD2KbXnkkZ0N9lsexYwq0Adu/dOa4OhQvTggkGLpBmSvifpRuDrknaRdL2kOZKuk7R5zre3pN/n62mSzs69qXslHVNX3oK6/FdKulDSXZLOlaT87J9z2mxJp9bKbWjXcEmnSLpN0jxJn2yS5wxJsyTdLunkuvT/kXRHtjslpx2Uy7pF0tW9/GNcpYkeXDDYeQ2wu+2lWRdsL9tLJO0H/DfwniY2W5D2L04A7pZ0hu3FDXl2ALYCHgGuBfaQNAs4E3ij7fsknddNm44CpgDb57as2STP52w/k/dTXiZpW+Bh4N3AFrad5YAAvgC8zfbDdWlBLxA9uGCwc4Htpfl6EnCBpNuAb5EcVDP+YHtRPij4CWCdJnlusv2PLKo4l+SwtgDutX1fztOdg9sPOLM2ZLb9TJM875V0M0kFYyuS9PZ8kvTPDyQdALyU814LzJD0YWB4N3UGJQgHFwx2Xqy7/jJwhe2tgXdSdxhJA4vqrpfSfKRSJE8pJG1M2lq0r+1tgT8AY7JD3AW4EHgHcBGA7aOBk0iKtbPzie5BLxAOLhhKTCIN8yDtT+xt7gZeK2lKvj+4m3yXAh+RNAKgyRB1Iskxz5e0DunAFCSNBybZ/iPw76RzBpC0ie0bbX8BeJIS0txBc2IOLhhKfB04R9JJpF5Rr2L7ZUkfAy6S9CIws5usZwGbAfMkLSbJai8/lNj2LZLmAHcBD5GGoJDmBH+TT28XcHxO/4akTXPaZcAtvftmqy6xVSsI6pA03vaCvKr6HeBvtr810O0KyhFD1CDoyoclzQVuJw2Jzxzg9gQViB5cEAQdS/TggiDoWMLBBUHQsYSDC4KgYwkHFwRBxxIOLgiCjiUcXBAEHcv/BzH8qcZKWC3OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plot similarities\n",
    "plt.imshow(similarities.detach().numpy())\n",
    "classnames = sorted(os.listdir('fruits/'))\n",
    "plt.xticks(np.arange(len(classnames)), classnames, rotation=90)\n",
    "plt.yticks(np.arange(len(classnames)), classnames)\n",
    "plt.xlabel('Training class')\n",
    "plt.ylabel('Testing class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpB2SPqscqTk"
   },
   "source": [
    "Task 7: Classification Accuracy\n",
    "-------------------------------\n",
    "\n",
    "Compute the classification accuracy by checking if the class of highest similarity for a test sample is the correct class.\n",
    "\n",
    "通过检查测试样本中相似度最高的类是否为正确的类来计算分类的准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9O36zlSScqTk",
    "outputId": "a9129379-a538-44fc-9608-706c07ec25b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is tensor(0.7857)\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy for our small test set\n",
    "\n",
    "# correct = 0\n",
    "# for row in range(O):\n",
    "#   max_index = similarities[row].argmax()\n",
    "#   if (max_index.item() == row):\n",
    "#     correct += 1;\n",
    "# accuracy = correct / O\n",
    "\n",
    "same = similarities.argmax(dim=1) == torch.tensor(list(test_features.keys()))\n",
    "accuracy = sum(same) / len(same)\n",
    "print(\"Accuracy is\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYCmVcUdcqTk"
   },
   "source": [
    "Task 8: Find Misclassified Images and Classes\n",
    "----------------------------------------------\n",
    "\n",
    "Find the test samples that are incorrectly classified. \n",
    "Get the class names (not only indexes) and write the names of the test sample class as well as the class that it was classified as.\n",
    "\n",
    "What are the two most dissimilar classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLFAOugQcqTk",
    "outputId": "d7b1ed29-ed33-4e3c-8058-284d317dfe5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classnames: ['apple', 'banana', 'carrot', 'corn', 'garlic', 'ginger', 'kiwi', 'lemon', 'onion', 'orange', 'pear', 'potato', 'tomato', 'watermelon']\n",
      "tensor([ 0,  1,  2,  3,  4, 11,  6,  9,  4,  9, 10, 11, 12, 13])\n",
      "\n",
      "all misclassified test images and print their real and predicted class name:\n",
      "Real: ginger | predict: potato\n",
      "Real: lemon | predict: orange\n",
      "Real: onion | predict: garlic\n",
      "\n",
      "most dissimilar training and test class and print their names:\n",
      "potato | carrot\n"
     ]
    }
   ],
   "source": [
    "classnames = testset.classes ### 好像是根据 subfolder 寻找的，生成一个 list\n",
    "print(\"classnames:\",classnames)\n",
    "# find all misclassified test images and print their real and predicted class name\n",
    "real_keys = torch.tensor(list(test_features.keys()))\n",
    "pred_keys = similarities.argmax(dim=1) ### 为什么答案给 dim=0 ？？？给错了，就应该是 dim=1\n",
    "print(pred_keys)\n",
    "print(\"\\nall misclassified test images and print their real and predicted class name:\")\n",
    "for key in real_keys:\n",
    "  if key != pred_keys[key]:\n",
    "    print(\"Real:\",classnames[key],\"| predict:\",classnames[pred_keys[key]])\n",
    "\n",
    "\n",
    "# find the pair of most dissimilar training and test class and print their names\n",
    "\n",
    "print(\"\\nmost dissimilar training and test class and print their names:\")\n",
    "# 为什么矩阵的argmax返回的是一个整数？\n",
    "idx = similarities.argmin().item()\n",
    "\n",
    "row = idx // O\n",
    "col = idx % O\n",
    "print(classnames[row],\"|\",classnames[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1fLmdSCQWIy",
    "outputId": "b6fe941b-4f87-4eea-a105-9b5775a1c287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4, 11,  6,  9,  4,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4JwOWJYWV5o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL-Assignment07.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
